{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: spec must be of type dict, ServerlessSpec, or PodSpec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Function to extract text from PDF files in a directory\n",
    "def extract_text_from_pdfs(directory):\n",
    "    pdf_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.pdf')]\n",
    "    extracted_text = []\n",
    "    for file_path in pdf_files:\n",
    "        # Open the PDF file\n",
    "        with fitz.open(file_path) as pdf_doc:\n",
    "            text = \"\"\n",
    "            # Iterate through each page\n",
    "            for page_num in range(len(pdf_doc)):\n",
    "                page = pdf_doc.load_page(page_num)\n",
    "                text += page.get_text()\n",
    "            extracted_text.append(text)\n",
    "    return extracted_text\n",
    "\n",
    "# Function to generate embeddings for text chunks\n",
    "def generate_embeddings(text_chunks, model):\n",
    "    embeddings = []\n",
    "    for chunk in text_chunks:\n",
    "        # Generate embedding for each text chunk\n",
    "        embedding = model.encode(chunk)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "try:\n",
    "    # Initialize Pinecone client with API Key from environment variable\n",
    "    pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "\n",
    "    # Assuming 'data/' is the directory containing PDF files\n",
    "    pdf_directory = 'data/'\n",
    "\n",
    "    # Extract text from PDF files in the directory\n",
    "    text_chunks = extract_text_from_pdfs(pdf_directory)\n",
    "\n",
    "    # Load Hugging Face embeddings model\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Generate embeddings for each text chunk\n",
    "    embeddings = generate_embeddings(text_chunks, model)\n",
    "\n",
    "    # Index name\n",
    "    index_name = \"medical-chatbot\"\n",
    "\n",
    "    # Dimensionality of the embeddings\n",
    "    dimension = 384\n",
    "\n",
    "    # Index specification\n",
    "    spec = None  # You can specify the index specification according to your requirements\n",
    "\n",
    "    # Create an index with the specified name, dimension, and spec\n",
    "    pc.create_index(index_name, dimension=dimension, spec=spec)\n",
    "\n",
    "    # Upsert embeddings into the index\n",
    "    pc.upsert(index_name, embeddings)\n",
    "\n",
    "    # Now you can perform operations on the created index like querying, updating, etc.\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: (422)\n",
      "Reason: unknown\n",
      "HTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'X-Cloud-Trace-Context': 'bc72cdefda94a7605dd108a685986558', 'Date': 'Wed, 27 Mar 2024 19:44:14 GMT', 'Server': 'Google Frontend', 'Content-Length': '139', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: Failed to deserialize the JSON body into the target type: spec: unknown variant `cloud`, expected `pod` or `serverless` at line 1 column 62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Function to extract text from PDF files in a directory\n",
    "def extract_text_from_pdfs(directory):\n",
    "    pdf_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.pdf')]\n",
    "    extracted_text = []\n",
    "    for file_path in pdf_files:\n",
    "        # Open the PDF file\n",
    "        with fitz.open(file_path) as pdf_doc:\n",
    "            text = \"\"\n",
    "            # Iterate through each page\n",
    "            for page_num in range(len(pdf_doc)):\n",
    "                page = pdf_doc.load_page(page_num)\n",
    "                text += page.get_text()\n",
    "            extracted_text.append(text)\n",
    "    return extracted_text\n",
    "\n",
    "# Function to generate embeddings for text chunks\n",
    "def generate_embeddings(text_chunks, model):\n",
    "    embeddings = []\n",
    "    for chunk in text_chunks:\n",
    "        # Generate embedding for each text chunk\n",
    "        embedding = model.encode(chunk)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "try:\n",
    "    # Initialize Pinecone client with API Key from environment variable\n",
    "    pc = Pinecone(api_key=os.environ.get('5d30ff0e-6bc6-41f4-8f3e-5654d3b4a131'))\n",
    "\n",
    "    # Assuming 'data/' is the directory containing PDF files\n",
    "    pdf_directory = 'data/'\n",
    "\n",
    "    # Extract text from PDF files in the directory\n",
    "    text_chunks = extract_text_from_pdfs(pdf_directory)\n",
    "\n",
    "    # Load Hugging Face embeddings model\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Generate embeddings for each text chunk\n",
    "    embeddings = generate_embeddings(text_chunks, model)\n",
    "\n",
    "    # Index name\n",
    "    index_name = \"medical-chatbot\"\n",
    "\n",
    "    # Dimensionality of the embeddings\n",
    "    dimension = 384\n",
    "\n",
    "    # Index specification (example: serverless index in AWS us-west-2 region)\n",
    "    spec = {\"cloud\": \"aws\", \"region\": \"Iowa (us-central1)\"}\n",
    "\n",
    "    # Create an index with the specified name, dimension, and spec\n",
    "    pc.create_index(index_name, dimension=dimension, spec=spec)\n",
    "\n",
    "    # Upsert embeddings into the index\n",
    "    pc.upsert(index_name, embeddings)\n",
    "\n",
    "    # Now you can perform operations on the created index like querying, updating, etc.\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
